{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63df5577",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53964f90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    #GENERIC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "from pprint import pprint\n",
    "    #PRE PROCESSING\n",
    "import re\n",
    "import nltk  \n",
    "import collections\n",
    "from nltk.corpus import stopwords\n",
    "    #Embedding\n",
    "from gensim.models import KeyedVectors\n",
    "import operator\n",
    "    #Sentiment Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "    #Finbert\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400008a1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Change Directory to the OS Folder\n",
    "os.chdir(r\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a83b46",
   "metadata": {},
   "source": [
    "# **Labelled Data Exploration**\n",
    "\n",
    "Two Datasets:\n",
    "> **FinancialPhraseBank** as used in Malo, P., Sinha, A., Takala, P., Korhonen, P. and Wallenius, J. (2014): “Good debt or bad debt: Detecting semantic orientations in economic texts.” Journal of the American Society for Information Science and Technology https://arxiv.org/abs/1307.5336  |  https://www.kaggle.com/ankurzing/sentiment-analysis-for-financial-news/version/5\n",
    "\n",
    "\n",
    "> **SemEval2017** Task 5: Fine-Grained Sentiment Analysis on Financial Microblogs and News (Cortis et al., 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee46858a",
   "metadata": {},
   "source": [
    "## Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef09b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset from FinancialPhraseBank\n",
    "FinancialPhraseBank = pd.read_csv(\"0)Headlines_Data_OG/FinancialPhraseBank.csv\", header=None, encoding = \"ISO-8859-1\")\n",
    "display(FinancialPhraseBank.shape)\n",
    "display(FinancialPhraseBank.head(3))\n",
    "#Dataset from SemEval2017 Task 5\n",
    "    #Traing Data\n",
    "SemEval_Training = pd.read_json(\"0)Headlines_Data_OG/SemEval2017_Trainingdata.json\")\n",
    "display(SemEval_Training.shape)\n",
    "display(SemEval_Training.head(3))\n",
    "    #Trial Data\n",
    "SemEval_Trial = pd.read_json(\"0)Headlines_Data_OG/SemEval2017_Trialdata.json\",)\n",
    "display(SemEval_Trial.shape)\n",
    "display(SemEval_Trial.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265c0f8",
   "metadata": {},
   "source": [
    " * Individual Analysis of each source of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90832d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # FinancialPhraseBank Data\n",
    "FinancialPhraseBank[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ea1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #SemEval Data\n",
    "SemEval = pd.concat([SemEval_Training,SemEval_Trial], ignore_index=True)\n",
    "    # Distribution of sentiment\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "SemEval[\"sentiment\"].hist(bins=50, ax=ax1)\n",
    "ax1.set_xlabel('Sentiment')\n",
    "ax1.set_ylabel('Sample')\n",
    "ax1.set_title('Sentiment distribution')\n",
    "plt.xlim(-1,1)\n",
    "plt.show()\n",
    "    # Healines Examples\n",
    "for sent_value in np.linspace(-1,1,21):\n",
    "        temp_df = SemEval.iloc[(SemEval['sentiment']-sent_value).abs().argsort()[:1]]\n",
    "        display(f'Sentiment {round(temp_df.iloc[0][\"sentiment\"],2)}  | Title: {temp_df.iloc[0][\"title\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13371334",
   "metadata": {},
   "source": [
    "## Compiled Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102a2b2",
   "metadata": {},
   "source": [
    " * Main Data Adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404370e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Data Adjutments\n",
    "    #Data Copies\n",
    "FinancialPhraseBank_0 = FinancialPhraseBank.copy()\n",
    "SemEval_0 = SemEval.copy()\n",
    "    #Renaming columns\n",
    "FinancialPhraseBank_0.rename(columns = {0: \"sentiment\", 1: \"title\"}, inplace = True) \n",
    "    #Eliminating Irrelevant Columns\n",
    "SemEval_0.drop(['id','company'], axis=1, inplace=True)\n",
    "    # Creating Sent Variable (pos 1; neg -1; neutral 0) Sent \n",
    "                #Note.For semeval data values <0 will be negative, >0 positive and the remained neutral\n",
    "FinancialPhraseBank_0[\"Sent\"] = np.where(FinancialPhraseBank_0[\"sentiment\"]==\"positive\",1,np.where(FinancialPhraseBank_0[\"sentiment\"]==\"negative\",-1,0))\n",
    "SemEval_0[\"Sent\"] = np.where(SemEval_0[\"sentiment\"]>0,1,np.where(SemEval_0[\"sentiment\"]<0,-1,0))          \n",
    "    #Join together the datframe\n",
    "headlines_sent_0 = pd.concat([FinancialPhraseBank_0, SemEval_0], ignore_index=True)\n",
    "    #Adjusting Duplicates (for SemEval some titles refer to multiple companies and so are displayed multiple times)\n",
    "headlines_sent_0['Duplicate_Title'] = headlines_sent_0.groupby('title')['title'].transform('count')\n",
    "headlines_sent_1 = headlines_sent_0[headlines_sent_0['Duplicate_Title']<2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Duplicated: \", len(headlines_sent_0))\n",
    "print(\"NO Duplicated: \", len(headlines_sent_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaba8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Data\n",
    "save_check = input(\"Save Data?\")\n",
    "if save_check == \"yes\":\n",
    "    with open(\"1)Transformed_Headlines/IS_Headlines_Data\", \"wb\") as fp:   \n",
    "        pickle.dump(headlines_sent_1, fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc660a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(headlines_sent_1.shape)\n",
    "display(headlines_sent_1.head(3))\n",
    "display(headlines_sent_1[\"Sent\"].value_counts()) #Sentiment Distribution (unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca92d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_sent_1[headlines_sent_1[\"Sent\"]==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc257cf2",
   "metadata": {},
   "source": [
    "# Functions for generic pre-processing\n",
    "\n",
    "Useful Links\n",
    "\n",
    "1) https://dylancastillo.co/nlp-snippets-clean-and-tokenize-text-with-python/#:~:text=Remove%20all%20special%20characters%20and%20punctuation%20In%20cases,import%20re%20sample_text%20%3D%20%22Sample%20text%20123%20%21%21%21%21\n",
    "\n",
    "2) https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text, multiexpression_dic=[], stopwords=None, special_char=False, numbers=True, lowercase=False, stemm=False, lemm=False):\n",
    "    '''Preprocess a string. All transformation can be chosen through arguments.\n",
    "    :parameter\n",
    "    :param text_input: string - sentence/corpus to be processed\n",
    "    :param numbers: bool - whether numbers are removed or not\n",
    "    :param special_char: bool - whether special characters and punctuation are removed or not\n",
    "    :param lowercase: bool - whether  words are converted to lowercase or not   \n",
    "    :param stopwords: list - list of stopwords to remove\n",
    "    :param stemm: bool - whether stemming is to be applied\n",
    "    :param lemm: bool - whether lemmitisation is to be applied\n",
    "    :param min_size: int - minimum size of words included (inclusive)\n",
    "    :param tokenize: bool - whether it is to tokenize the final text\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # MultiExpression Words (1st step)\n",
    "    for key, value in multiexpression_dic.items():\n",
    "        if key in text:\n",
    "            text = text.replace(key,value)\n",
    "    # Word Tokenize (2st step)\n",
    "    text = nltk.word_tokenize(text)    \n",
    "    #StopWord Removal (3rd step)\n",
    "    if stopwords is not None:\n",
    "        text = [word for word in text if word not in stopwords]    \n",
    "    # Punctuation & Special Character removal (except those between numbers and those in multiexpressions)\n",
    "    if special_char == True:\n",
    "        multiexpressions = list(multiexpression_dic.values())\n",
    "        text = [re.sub(r\"(?<!\\d)[.,;:](?!\\d)\", \"\", word) if word not in multiexpressions else word for word in text] \n",
    "        text = [word for word in text if word!=\"\"]   \n",
    "    # Numbers removal\n",
    "    if numbers == True:\n",
    "        text = [re.sub('\\d', '#', str(word)) for word in text] \n",
    "    # Conversion to lowercase\n",
    "    if lowercase == True:\n",
    "        text =  [word.lower() for word in text]       \n",
    "    # Stemming (remove -ing, -ly, ...)\n",
    "    if stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        text = [ps.stem(word) for word in text.split()]\n",
    "    # Lemmatisation (convert the word into root word)\n",
    "    if lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        text = [lem.lemmatize(word) for word in text.split()]     \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee975143",
   "metadata": {},
   "source": [
    "# Tables w Performace of Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7836200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Data\n",
    "load_data = input(\"Load Table Data?\")\n",
    "if load_data.lower() == \"yes\":\n",
    "    ML_table_Full = pd.read_excel(\"3)Table_Plots/ML_Performance.xlsx\", index_col=0)\n",
    "##Initiate New ML_table\n",
    "reset_data = input(\"Reset Table Data?\")\n",
    "if reset_data.lower() == \"yes\":\n",
    "    ML_table_Full = pd.DataFrame([], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "##Save Data\n",
    "save_data = input(\"Save the Data?\")\n",
    "if save_data.lower() == \"yes\":\n",
    "    print(\"Saving\")\n",
    "    datestring_time = datetime.strftime(datetime.now(),\"%m_%d_%Y\")\n",
    "    writer = pd.ExcelWriter(\"3)Table_Plots/\"+str(datestring_time) + \"__ML_Performance.xlsx\", engine='xlsxwriter')\n",
    "    ML_table_Full = ML_table_Full.drop_duplicates()\n",
    "    ML_table_Full.to_excel(writer, sheet_name='ML')  \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc088148",
   "metadata": {},
   "source": [
    "# Word2Vec Embeding + ML\n",
    "\n",
    "\n",
    "> **Google word2vec >**  https://code.google.com/archive/p/word2vec/\n",
    "\n",
    "> **Intuition of Models >**  https://thinkinfi.com/simple-doc2vec-explained/\n",
    "\n",
    "> **Averaging vectors intuition >**https://stats.stackexchange.com/questions/318882/what-does-average-of-word2vec-vector-mean/318891\n",
    "\n",
    "> **Averaging vectors papers >** \"Sentiment  Analysis  of  Twitter  Messages  using \n",
    "Word2vec  by  Weighted  Average\" (Kamel, 2019)\n",
    "\n",
    "> **Pre-Processing Specs >** https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "\n",
    "> **Intuition >**https://wiki.pathmind.com/word2vec#:~:text=Word2vec%20is%20a%20two%2Dlayer,deep%20neural%20networks%20can%20understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1444d",
   "metadata": {},
   "source": [
    "## Specific Functions for embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cfd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_coverage(vocab,model):\n",
    "    '''Percentage of words in vocabulary that are in model selected. And percentage of tottal text.\n",
    "    :param vocab: dictionary with count of words in data to be vectorized\n",
    "    :param model: pretrained model used\n",
    "    '''\n",
    "    common_words = {}\n",
    "    specific_vocab = {}\n",
    "    n_words_common = 0\n",
    "    n_specific_vocab = 0\n",
    "    for word in (vocab):\n",
    "        try:\n",
    "            common_words[word] = model[word]\n",
    "            n_words_common += vocab[word]\n",
    "        except:\n",
    "            specific_vocab[word] = vocab[word]\n",
    "            n_specific_vocab += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(common_words) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(n_words_common / (n_words_common + n_specific_vocab)))\n",
    "    sorted_x = sorted(specific_vocab.items(), key=operator.itemgetter(1))[::-1]\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc748310",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a3403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading headlines\n",
    "with open(\"1)Transformed_Headlines/IS_Headlines_Data\", \"rb\") as fp:  \n",
    "    IS_headlines = pickle.load(fp)\n",
    "#Load Google vocab\n",
    "with open(\"PreTrainedModels/Word2Vec_Vocab\", \"rb\") as fp:  \n",
    "    Vocab_in_google_model = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf67b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "    #Specifc dictionaries with correction\n",
    "stop_words_google = [\"to\",\"of\",\"and\",\"a\"]\n",
    "    #GET multiexpressions & organize them into a dictionary as non processed: processed format\n",
    "mulitword_expressions_google = [vocab for vocab in Vocab_in_google_model if (\"_\" in vocab) & (len(vocab[:vocab.find(\"_\")])>=2) & (len(vocab[vocab.find(\"_\")+1:])>=2)] \n",
    "multiexpression_google_dic = {\" \".join(exp.split(\"_\")):exp for exp in mulitword_expressions_google}\n",
    "    #Processing\n",
    "IS_headlines[\"Processed_Text\"] = IS_headlines.progress_apply(lambda x:text_processing(x[\"title\"], multiexpression_dic=multiexpression_google_dic, stopwords=stop_words_google, special_char=True, numbers=True, lowercase=False, stemm=False, lemm=False),axis=1)\n",
    "headline_processed_0 = list(IS_headlines[\"Processed_Text\"])\n",
    "\n",
    "#Save Processed Features\n",
    "save_check = input(\"Save Processed Sentences?\")\n",
    "if save_check == \"yes\":\n",
    "    with open(\"1)Transformed_Headlines/IS_Headlines_Data_+token\", \"wb\") as fp:   \n",
    "        pickle.dump(IS_headlines, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc41a78",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabfcd0e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#GET Processed Headlines\n",
    "with open(\"1)Transformed_Headlines/IS_Data_+token\", \"rb\") as fp:  \n",
    "    IS_headlines = pickle.load(fp)\n",
    "\n",
    "#ELIMINATE NEUTRAL FOR BINARY MODEL\n",
    "model_type = input(\"USE BINARY MODEL?\")\n",
    "if model_type == \"yes\":\n",
    "    IS_headlines = IS_headlines[IS_headlines[\"Sent\"]!=0].copy()\n",
    "\n",
    "#LIST of Headlines & Vocabulary\n",
    "headline_processed_0 = list(IS_headlines[\"Processed_Text\"])\n",
    "headline_processed_0_vocab = build_vocab(headline_processed_0) \n",
    "\n",
    "#Check  empty lists\n",
    "IS_headlines[IS_headlines.apply(lambda x: len(x[\"Processed_Text\"])<2, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7d8dd6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load google word2vec trained model, saved in desktop\n",
    "filename = \"GoogleNews-vectors-negative300.bin\"\n",
    "google_model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9578e1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Check covergae of pretrained model given current vocabulary\n",
    "coverage_check = input(\"Check coverage of model?\")\n",
    "if coverage_check == \"yes\":\n",
    "    word_coverage = embedding_coverage(headline_processed_0_vocab,google_model)\n",
    "    display(word_coverage)\n",
    "    \n",
    "#Get and save googel vocab\n",
    "Vocab_in_google_model = list(google_model.index_to_key)\n",
    "save_check = input(\"Save Word2Vec Vocabulary?\")\n",
    "if save_check == \"yes\":\n",
    "    with open(\"PreTrainedModels/Word2Vec_Vocab\", \"wb\") as fp:   \n",
    "        pickle.dump(Vocab_in_google_model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd8c0f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Going from word vector to sentence vectors......\n",
    "IS_headlines[\"Vectorized_Text\"] = IS_headlines.progress_apply(lambda x: np.mean([google_model[token] for token in x[\"Processed_Text\"] if token in Vocab_in_google_model], axis=0),axis=1)\n",
    "IS_headlines = IS_headlines[IS_headlines.apply(lambda x: type(x[\"Vectorized_Text\"])!=np.float64, axis=1)] #take out empty arrays\n",
    "#SAVE sentence vectors & google vocab\n",
    "save_check = input(\"Save Vectorized Sentences?\")\n",
    "if save_check == \"yes\":\n",
    "    with open(\"1)Transformed_Headlines/IS_Data_+token_+vector\", \"wb\") as fp:   \n",
    "        pickle.dump(IS_headlines, fp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780dea77",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Check model closest words to given user chosen word\n",
    "check = input(\"Check word for model closest?\")\n",
    "if check == \"yes\":\n",
    "    sim_words = google_model.most_similar('rise', topn = 10)\n",
    "    sim_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8ab9d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sentiment Models (TRAINING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785e0ae",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading Processed Headlines\n",
    "with open(\"1)Transformed_Headlines/IS_Data_+token_+vector\", \"rb\") as fp:  \n",
    "    IS_headlines_processed = pickle.load(fp)\n",
    "    \n",
    "# Split Dataset into Traing and Test\n",
    "headlines_train, headlines_test, sent_train, sent_test = train_test_split(list(IS_headlines_processed[\"Vectorized_Text\"]), list(IS_headlines_processed[\"Sent\"]), \n",
    "                                                          test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afee73",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Baseline Model\n",
    "Based on Majority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267b57f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Majority baseline\n",
    "display(pd.Series(sent_train).value_counts())\n",
    "display(pd.Series(sent_test).value_counts())\n",
    "# Generate majority baseline dataframe\n",
    "y_train_pred_baseline = [1]*len(sent_train)\n",
    "y_test_pred_baseline = [1]*len(sent_test)\n",
    "\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "p, r, f, s = precision_recall_fscore_support(sent_train, y_train_pred_baseline, average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(p))\n",
    "print(\"Recall: {:.2%}\".format(r))\n",
    "print(\"F score: {:.2%}\".format(f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "p, r, f, s = precision_recall_fscore_support(sent_test, y_test_pred_baseline, average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(p))\n",
    "print(\"Recall: {:.2%}\".format(r))\n",
    "print(\"F score: {:.2%}\".format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97277620",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Baseline Model\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, y_train_pred_baseline, average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, y_test_pred_baseline, average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Baseline Model\",\"-\",\"-\",\"-\",train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e2bdc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dee30c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d56ca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Linear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd3f0f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "LinearSVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [2.5,3,3.2,3.5,3.7,4],\n",
    "    'kernel':[\"linear\"],\n",
    "    'decision_function_shape':[\"ovo\", \"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_LinearSVC = GridSearchCV(LinearSVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_LinearSVC.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_LinearSVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_LinearSVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_LinearSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_LinearSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_LinearSVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66647c3d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_LinearSVC.best_estimator_, '2)Sentiment_Models/LinearSVC_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ad10d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_LinearSVC = load(\"2)Sentiment_Models/LinearSVC_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_LinearSVC, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Linear SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_LinearSVC.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_LinearSVC.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Linear SVC\",Best_LinearSVC,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce46671",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Poly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd776c4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "PolySVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [4,4.5],\n",
    "    'kernel':[\"poly\"],\n",
    "    'degree':[2,3],\n",
    "    'gamma':[\"scale\",0.7,0.8],\n",
    "    'decision_function_shape':[\"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "# cross-validation\n",
    "grid_search_PolySVC = GridSearchCV(PolySVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_PolySVC.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_PolySVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_PolySVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_PolySVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_PolySVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_PolySVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb1ffa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_PolySVC.best_estimator_, '2)Sentiment_Models/PolySVC_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2ae59",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_PolySVC = load(\"2)Sentiment_Models/PolySVC_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_PolySVC, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Poly SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_PolySVC.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_PolySVC.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Poly SVC\",Best_PolySVC,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b37e5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Rbf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b9bd6a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "RbfSVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [3.5,3.7,3.8,3.9,4],\n",
    "    'kernel':[\"rbf\"],\n",
    "    'decision_function_shape':[\"ovo\", \"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "# 10-fold cross-validation\n",
    "grid_search_RbfSVC = GridSearchCV(RbfSVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_RbfSVC.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_RbfSVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_RbfSVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_RbfSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_RbfSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_RbfSVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe9f4b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_RbfSVC.best_estimator_, '2)Sentiment_Models/RbfSVC_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97183b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_RbfSVC = load(\"2)Sentiment_Models/RbfSVC_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_RbfSVC, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Rbf SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_RbfSVC.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_RbfSVC.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Rbf SVC\",Best_RbfSVC,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35143a12",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Sigmoid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9973bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "SigmoidSVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [0.5,0.55,0.6,0.65,0.7,0.8,],\n",
    "    'kernel':[\"sigmoid\"],\n",
    "    #'gamma ':[\"scale\", \"auto\"],\n",
    "    'decision_function_shape':[\"ovo\", \"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "# 10-fold cross-validation\n",
    "grid_search_SigmoidSVC = GridSearchCV(SigmoidSVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_SigmoidSVC.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_SigmoidSVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_SigmoidSVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_SigmoidSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_SigmoidSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_SigmoidSVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80019c5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_SigmoidSVC.best_estimator_, '2)Sentiment_Models/SigmoidSVC_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2b1b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_SigmoidSVC = load(\"2)Sentiment_Models/SigmoidSVC_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_SigmoidSVC, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Sigmoid SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_SigmoidSVC.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_SigmoidSVC.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Sigmoid SVC\",Best_SigmoidSVC,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c728e0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3932d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec2155e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "RFC = RandomForestClassifier()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'max_features':[100,200],\n",
    "    'max_depth':[9],\n",
    "    'min_samples_leaf':[4],\n",
    "    #'max_features':[\"auto\", \"sqrt\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_RFC = GridSearchCV(RFC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_RFC.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_RFC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_RFC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_RFC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_RFC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_RFC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ecec2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_RFC.best_estimator_, '2)Sentiment_Models/RFC_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059ab936",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_RFC = load(\"2)Sentiment_Models/RFC_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_RFC, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Random Forest\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_RFC.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_RFC.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Random Forest\",Best_RFC,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5cd83",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ea0d67",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe061451",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "LR = LogisticRegression()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [4,4.5,5,5.5],\n",
    "    'l1_ratio': [0.4,0.5,0.6],\n",
    "    'penalty':[\"elasticnet\"],  #  elasticnet\n",
    "    'solver':[\"saga\"],  #  \"saga\"  \"sag\", \"lbfgs\", \"newton-cg\"\n",
    "    'max_iter': [200,500],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_LR = GridSearchCV(LR, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_LR.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_LR.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_LR.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_LR.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_LR.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_LR.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a214443",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_LR.best_estimator_, '2)Sentiment_Models/LR_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47575675",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_LR = load(\"2)Sentiment_Models/LR_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_LR, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Logistic Regression\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_LR.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_LR.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Logistic Regression\",Best_LR,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dcd30a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c68b05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9d1ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "NB = GaussianNB()\n",
    "# grid search \n",
    "param_grid = {\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_NB = GridSearchCV(NB, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_NB.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_NB.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_NB.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_NB.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_NB.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_NB.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f03e8e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_NB.best_estimator_, '2)Sentiment_Models/NB_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd8b0f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_NB = load(\"2)Sentiment_Models/NB_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_NB, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Naive Bayes\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_NB.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_NB.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Naive Bayes\",Best_NB,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9327201b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20923e41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "?MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45d0e2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "NN = MLPClassifier()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50),(100,)],\n",
    "    'activation':[\"relu\"],\n",
    "    'alpha':[0.06,0.07],\n",
    "    'learning_rate':[\"invscaling\"],  #\"constant\", \"invscaling\", \"adaptive\"\n",
    "    'max_iter':[1000],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_NN = GridSearchCV(NN, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_NN.fit(headlines_train, sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_NN.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_NN.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_NN.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_NN.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_NN.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5de26f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_NN.best_estimator_, '2)Sentiment_Models/NN_2class.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43be58",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_NN = load(\"2)Sentiment_Models/NN_2class.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_NN, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit(headlines_train, sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Neural Networks\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_NN.predict(headlines_train), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_NN.predict(headlines_test), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Neural Networks\",Best_NN,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ef4559",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# FinBert\n",
    "\n",
    "Implementations Model:\n",
    "> **Financial News Sentiment Analysis using FinBERT  >** https://medium.com/@ravirajshinde2000/financial-news-sentiment-analysis-using-finbert-25afcc95e65f\n",
    "\n",
    "> **SentenceTransformers Documentation>**https://www.sbert.net/\n",
    "\n",
    "> **Training Overview>**https://www.sbert.net/docs/training/overview.html/\n",
    "\n",
    "> **How to Train BERT  >** https://towardsdatascience.com/how-to-train-bert-aaad00533168\n",
    "\n",
    "> **Richer Sentence Embeddings using Sentence-BERT — Part I>** https://medium.com/genei-technology/richer-sentence-embeddings-using-sentence-bert-part-i-ce1d9e0b1343"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee42ed0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Specific Functions for embedding Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf3733d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def FinBERT_tokenization_outputlayer(sentence):\n",
    "    '''A 3x1 layer is outputed of which the first value represents neutral the second positive and the third negative sentiment  {0:'neutral', 1:'positive',2:'negative'}'''\n",
    "    try:\n",
    "        #Tokenizing\n",
    "        inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True)\n",
    "        #Output Layes\n",
    "        outputs = finbert(**inputs)[0]\n",
    "        array_output = outputs.detach().numpy() \n",
    "        return array_output\n",
    "    except Exception as ex:\n",
    "        print(\"Error {} for sentence >  {}\".format(ex,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dac08f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading pre-trained model and tokenizer\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone',num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe413c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#?tokenizer\n",
    "#pprint(vars(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0d7ac8",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Initiating Models data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf91a3c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Loading Processed Headlines\n",
    "with open(\"1)Transformed_Headlines/IS_Data_Finbert\", \"rb\") as fp:  \n",
    "    IS_headlines_processed = pickle.load(fp)\n",
    "\n",
    "#Save Finbert outpu layer\n",
    "resave_output = input(\"RESave Finbert Output?\")\n",
    "if resave_output == \"yes\":\n",
    "    IS_headlines_processed[\"Finbert_output\"] = IS_headlines_processed.progress_apply(lambda x: FinBERT_tokenization_outputlayer(x[\"title\"]), axis=1)\n",
    "    with open(\"1)Transformed_Headlines/IS_Data_Complete\", \"wb\") as fp:   \n",
    "        pickle.dump(IS_headlines_processed, fp)  \n",
    "\n",
    "# Split Dataset into Traing and Test\n",
    "headlines_train, headlines_test, sent_train, sent_test = train_test_split(list(IS_headlines_processed[\"Finbert_output\"]), list(IS_headlines_processed[\"Sent\"]), \n",
    "                                                          test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76c3d3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Untoched Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9cb55a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "print(\"fINBERT \")\n",
    "labels = {0:1,1:-1}\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, [labels[np.argmax(h[0][1:])] for h in headlines_train] , average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test,[labels[np.argmax(h[0][1:])] for h in headlines_test], average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"fINBERT\",\"-\",\"-\",\"-\",train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6571ec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Finbert + ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4ca0b0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layers (SVM Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c5790",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "LinearSVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [3.7,4,4.1,4.2,4.3],\n",
    "    'kernel':[\"linear\"],\n",
    "    'decision_function_shape':[\"ovo\", \"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_LinearSVC = GridSearchCV(LinearSVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_LinearSVC.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_LinearSVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_LinearSVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_LinearSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_LinearSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_LinearSVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24cb526",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_LinearSVC.best_estimator_, '2)Sentiment_Models/LinearSVC_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd89cc89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_LinearSVC_Finbert = load(\"2)Sentiment_Models/LinearSVC_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_LinearSVC_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Linear SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_LinearSVC_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_LinearSVC_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Linear SVC\",Best_LinearSVC_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4aeeaf",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layers (Poly Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e829d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "PolySVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [0.3,0.4,0.5,0.6],\n",
    "    'kernel':[\"poly\"],\n",
    "    'degree':[3],\n",
    "    'gamma':[\"auto\"],\n",
    "    'decision_function_shape':[\"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_PolySVC = GridSearchCV(PolySVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_PolySVC.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_PolySVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_PolySVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_PolySVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_PolySVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_PolySVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef63e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_PolySVC.best_estimator_, '2)Sentiment_Models/PolySVC_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a52d959",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_PolySVC_Finbert = load(\"2)Sentiment_Models/PolySVC_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_PolySVC_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Linear SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_PolySVC_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_PolySVC_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Poly SVC\",Best_PolySVC_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f5a71",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layes (Rbf Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ace39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "RbfSVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [3,3.1,3.2,3.5,3.7],\n",
    "    'kernel':[\"rbf\"],\n",
    "    'decision_function_shape':[\"ovo\", \"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_RbfSVC = GridSearchCV(RbfSVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_RbfSVC.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_RbfSVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_RbfSVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_RbfSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_RbfSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_RbfSVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa76d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_RbfSVC.best_estimator_, '2)Sentiment_Models/RbfSVC_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0423479d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_RbfSVC_Finbert = load(\"2)Sentiment_Models/RbfSVC_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_RbfSVC_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Linear SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_RbfSVC_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_RbfSVC_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Rbf SVC\",Best_RbfSVC_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40875bff",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layes (Sigmoid Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21cba8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize SVC\n",
    "SigmoidSVC = SVC()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'C': [0.5,0.55,0.6,0.65,0.7,0.8,],\n",
    "    'kernel':[\"sigmoid\"],\n",
    "    'gamma':[\"scale\", \"auto\",0.1],\n",
    "    'decision_function_shape':[\"ovo\", \"ovr\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_SigmoidSVC = GridSearchCV(SigmoidSVC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_SigmoidSVC.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_SigmoidSVC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_SigmoidSVC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_SigmoidSVC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_SigmoidSVC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_SigmoidSVC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca19b07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_SigmoidSVC.best_estimator_, '2)Sentiment_Models/Sigmoid_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915d51e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_Sigmoid_Finbert = load(\"2)Sentiment_Models/Sigmoid_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_Sigmoid_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Linear SVC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_Sigmoid_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_Sigmoid_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Sigmoid SVC\",Best_Sigmoid_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43c5e1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layes (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed74a4c",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "NN = MLPClassifier()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(3,),(5,),(4,)],\n",
    "    'activation':[\"relu\"],\n",
    "    'alpha':[0.8,1,1.2],\n",
    "    'learning_rate':[\"invscaling\"],  #\"constant\", \"invscaling\", \"adaptive\"\n",
    "    'max_iter':[1000],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_NN = GridSearchCV(NN, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_NN.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_NN.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_NN.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_NN.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_NN.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_NN.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4235ef72",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_NN.best_estimator_, '2)Sentiment_Models/NN_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726c7c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_NN_Finbert = load(\"2)Sentiment_Models/NN_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_NN_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Neural Networks\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_NN_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_NN_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Neural Networks\",Best_NN_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72febc2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layes (Logistic Regression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e311aab2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "LR = LogisticRegression()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    #'C': [4,4.5,5,5.5],\n",
    "    #'l1_ratio': [0.4,0.5,0.6],\n",
    "    'penalty':[\"none\"],  #  \"elasticnet\", \"l2\", \"none\"\n",
    "    'solver':[\"sag\", \"lbfgs\", \"newton-cg\"],  #  \"saga\"  \"sag\", \"lbfgs\", \"newton-cg\"\n",
    "    'max_iter': [200,500],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_LR = GridSearchCV(LR, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_LR.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_LR.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_LR.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_LR.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_LR.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_LR.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb2319",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Best_LR_Finbert.predict(headlines_train[0][0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff633959",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Best_LR_Finbert.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16763274",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_LR.best_estimator_, '2)Sentiment_Models/LR_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d45cfd",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_LR_Finbert = load(\"2)Sentiment_Models/LR_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_LR_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Logistic Regression\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_LR_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_LR_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Logistic Regression\",Best_LR_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6f483",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cba85958",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Extra Layes (Random Forest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cbfa65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "RFC = RandomForestClassifier()\n",
    "# grid search \n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'max_features':[3],\n",
    "    'max_depth':[3],\n",
    "    #'min_samples_leaf':[4],\n",
    "    #'max_features':[\"auto\", \"sqrt\"],\n",
    "    'random_state': [42]\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_RFC = GridSearchCV(RFC, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_RFC.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_RFC.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_RFC.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_RFC.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_RFC.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_RFC.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a076c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_RFC.best_estimator_, '2)Sentiment_Models/RFC_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f9757",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_RFC_Finbert = load(\"2)Sentiment_Models/RFC_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_RFC_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"RFC\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_RFC_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_RFC_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert RFC\",Best_RFC_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c3190",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extra Layes (Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d6f74",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Initialize Random Forest\n",
    "NB = GaussianNB()\n",
    "# grid search \n",
    "param_grid = {\n",
    "}\n",
    "#cross-validation\n",
    "grid_search_NB = GridSearchCV(NB, param_grid, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "\n",
    "start = time.time()\n",
    "grid_search_NB.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "end = time.time() - start\n",
    "print(f\"Took {end} seconds\")\n",
    "# Print the set of best hyperparameters\n",
    "print(\"Best estimators\", grid_search_NB.best_estimator_)\n",
    "# Mean cross-validated score of the best_estimator\n",
    "print(\"Validation Score\", grid_search_NB.best_score_)\n",
    "#Print scores of all tests\n",
    "val_scores = grid_search_NB.cv_results_[\"mean_test_score\"]\n",
    "train_scores = grid_search_NB.cv_results_[\"mean_train_score\"]\n",
    "params = [str(x) for x in grid_search_NB.cv_results_[\"params\"]]\n",
    "for val_score, train_score, param in sorted(zip(val_scores, train_scores, params), reverse=True):\n",
    "    print('Val:{:.2%};  Train:{:.2%}; Param:{};'.format(val_score, train_score, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983969b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Store model\n",
    "save_model_best = input(\"Save model best params\")\n",
    "if save_model_best == \"yes\":\n",
    "    dump(grid_search_NB.best_estimator_, '2)Sentiment_Models/NB_2class_Finbert.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa54f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load best model and get statistics on the full train set and test\n",
    "##INitiate and store best model\n",
    "Best_NB_Finbert = load(\"2)Sentiment_Models/NB_2class_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_NB_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_train], sent_train)\n",
    "grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "val_score = grid_search_results[0][0]\n",
    "train_score = grid_search_results[0][1]\n",
    "##Full Train & Full Test/VAlidation\n",
    "print(\"Naive Bayes\")\n",
    "  #Train\n",
    "print(\"-----TRAIN-----\")\n",
    "train_p, train_r, train_f, train_s = precision_recall_fscore_support(sent_train, Best_NB_Finbert.predict([list(h[0]) for h in headlines_train]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(train_p))\n",
    "print(\"Recall: {:.2%}\".format(train_r))\n",
    "print(\"F score: {:.2%}\".format(train_f))\n",
    "  #Test\n",
    "print(\"-----TEST-----\")\n",
    "test_p, test_r, test_f, test_s = precision_recall_fscore_support(sent_test, Best_NB_Finbert.predict([list(h[0]) for h in headlines_test]), average=\"macro\")\n",
    "print(\"Precision: {:.2%}\".format(test_p))\n",
    "print(\"Recall: {:.2%}\".format(test_r))\n",
    "print(\"F score: {:.2%}\".format(test_f))\n",
    "##Append Data\n",
    "ML_table = pd.DataFrame([[\"Finbert Naive Bayes\",Best_NB_Finbert,train_score,val_score,train_f,test_f]], columns=[\"ML\",\"Params\",\"Mean Train\",\"Mean Test\",\"Train\",\"Validation\"])\n",
    "ML_table_Full = pd.concat([ML_table_Full,ML_table])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a100d",
   "metadata": {},
   "source": [
    "# Top Models \n",
    "Further Tests for Decision on Close Models\n",
    "\n",
    "> FinBERT with **SVM (rbf)** Vs FinBERT with **NN**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabcc76d",
   "metadata": {},
   "source": [
    "## Auxiliary Functions & Loading Models/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec52c1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Processed Headlines\n",
    "with open(\"1)Transformed_Headlines/IS_Data_Finbert\", \"rb\") as fp:  \n",
    "    IS_headlines_complete= pickle.load(fp)\n",
    "# Split Dataset into Traing and Test\n",
    "headlines_list = list(IS_headlines_complete[\"Finbert_output\"])\n",
    "sent_list = list(IS_headlines_complete[\"Sent\"])\n",
    "headlines_train, headlines_test, sent_train, sent_test = train_test_split(headlines_list, sent_list, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edac519",
   "metadata": {},
   "source": [
    "## Extra Cross Validation & Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.listdir(\"2)Sentiment_Models\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf35d371",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7f06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##INitiate \n",
    "Best_LinearSVC_Finbert = load(\"2)Sentiment_Models/RbfSVC_2class_wProb_Finbert.joblib\")\n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_LinearSVC_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_list], sent_list)\n",
    "#grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "\n",
    "#Show Values\n",
    "print(\"Linear SVC\")\n",
    "test_scores = gs_best.cv_results_[\"mean_test_score\"]\n",
    "train_scores = gs_best.cv_results_[\"mean_train_score\"]\n",
    "print(\"Test Scores: {}\".format(gs_best.cv_results_[\"mean_test_score\"]))\n",
    "print(\"Train Scores: {}\".format(gs_best.cv_results_[\"mean_train_score\"]))\n",
    "\n",
    "#List of scores of each splits\n",
    "test_splits_M1 = [gs_best.cv_results_[\"split\"+str(i)+\"_test_score\"] for i in range(5)]\n",
    "train_splits_M1 = [gs_best.cv_results_[\"split\"+str(i)+\"_train_score\"] for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50ce65",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8743f2c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##INitiate \n",
    "Best_Logistic_Finbert = load(\"2)Sentiment_Models/NN_2class_Finbert.joblib\") \n",
    "#Train the model (with CV)\n",
    "gs_best = GridSearchCV(Best_Logistic_Finbert, {}, cv=5,\n",
    "                           scoring='f1_macro', \n",
    "                           return_train_score=True,\n",
    "                           error_score= \"raise\") \n",
    "gs_best.fit([list(h[0]) for h in headlines_list], sent_list)\n",
    "#grid_search_results = sorted(zip(gs_best.cv_results_[\"mean_test_score\"], gs_best.cv_results_[\"mean_train_score\"], [str(x) for x in gs_best.cv_results_[\"params\"]]), reverse=True)\n",
    "\n",
    "#Show Values\n",
    "print(\"Linear SVC\")\n",
    "test_scores = gs_best.cv_results_[\"mean_test_score\"]\n",
    "train_scores = gs_best.cv_results_[\"mean_train_score\"]\n",
    "print(\"Test Scores: {}\".format(gs_best.cv_results_[\"mean_test_score\"]))\n",
    "print(\"Train Scores: {}\".format(gs_best.cv_results_[\"mean_train_score\"]))\n",
    "\n",
    "#List of scores of each splits\n",
    "test_splits_M2 = [gs_best.cv_results_[\"split\"+str(i)+\"_test_score\"] for i in range(5)]\n",
    "train_splits_M2 = [gs_best.cv_results_[\"split\"+str(i)+\"_train_score\"] for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c39fb4",
   "metadata": {},
   "source": [
    "## Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257228b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##INitiate \n",
    "Best_model = load(\"2)Sentiment_Models/RbfSVC_2class_wProb_Finbert.joblib\") \n",
    "\n",
    "# Printprecision, recall and f-score (of macro and by class)\n",
    "p, r, f, s = precision_recall_fscore_support(sent_test, Best_model.predict([list(h[0]) for h in headlines_test]), average=None)\n",
    "print(\"Precision: {}\".format(p))\n",
    "print(\"Recall: {}\".format(r))\n",
    "print(\"F score: {}\".format(f))\n",
    "print(\"Instances {}\".format(s))\n",
    "print(\"Accuracy {}\".format(accuracy_score(sent_test, Best_model.predict([list(h[0]) for h in headlines_test]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d4e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = plot_confusion_matrix(Best_model, [list(h[0]) for h in headlines_test], sent_test,\n",
    "                                 cmap=plt.cm.Greys,\n",
    "                                 normalize='true',\n",
    "                                 values_format=\".1%\")\n",
    "\n",
    "#conf_matrix.figure_.savefig('conf_mat.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_m = confusion_matrix(sent_test, Best_model.predict([list(h[0]) for h in headlines_test]), normalize='true')\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(conf_m, annot=True, fmt='.2%', ax=ax, cmap='Blues_r');  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.xaxis.set_ticklabels(['negative', 'positive']); ax.yaxis.set_ticklabels(['negative', 'positive']); \n",
    "\n",
    "ax.figure.savefig('svm_conf.png', transparent=True, dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc5ad1",
   "metadata": {},
   "source": [
    "# Processed data Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1879c",
   "metadata": {},
   "source": [
    "* Overview of data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d4bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Processed Headlines\n",
    "with open(\"1)Transformed_Headlines/IS_Data_Complete\", \"rb\") as fp:  \n",
    "    IS_headlines_processed = pickle.load(fp)\n",
    "#Displaying Data\n",
    "display(IS_headlines_processed.columns)\n",
    "display(IS_headlines_processed.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d32941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset into Traing and Test\n",
    "headlines_train, headlines_test, sent_train, sent_test = train_test_split(list(IS_headlines_processed[\"Processed_Text\"]), list(IS_headlines_processed[\"Sent\"]), \n",
    "                                                          test_size=0.2, random_state=42)\n",
    "print(\"----- Full -----\")\n",
    "size = len(IS_headlines_processed[\"Sent\"])\n",
    "print(\"Size: \", size)\n",
    "counts = collections.Counter(IS_headlines_processed[\"Sent\"])\n",
    "print(\"Value Count: \",counts)\n",
    "print(\"Value Percentage >  [1]:{:.0%} , [-1]:{:.0%}\".format(counts[1]/size,counts[-1]/size))\n",
    "\n",
    "print(\"----- Train -----\")\n",
    "size_train = len(sent_train)\n",
    "print(\"Size: \", size_train)\n",
    "train_counts = collections.Counter(sent_train)\n",
    "print(\"Value Count: \",train_counts)\n",
    "print(\"Value Percentage >  [1]:{:.0%} , [-1]:{:.0%}\".format(train_counts[1]/size_train,train_counts[-1]/size_train))\n",
    "      \n",
    "print(\"----- Test -----\")\n",
    "size_test = len(sent_test)\n",
    "print(\"Size: \", size_test)\n",
    "test_counts = collections.Counter(sent_test)\n",
    "print(\"Value Count: \",test_counts)\n",
    "print(\"Value Percentage >  [1]:{:.0%} , [-1]:{:.0%}\".format(test_counts[1]/size_test,test_counts[-1]/size_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693fe040",
   "metadata": {},
   "source": [
    "* Headlines word analysi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17b720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(headlines):\n",
    "    \"\"\"REturns dictionary with cout of occurence of each word in the full dataset.\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in headlines:\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ea70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Headlines Size statistics\n",
    "print('Average word length of Headlines is {0:.0f}.'.format(np.mean([len(headline) for headline in IS_headlines_processed[\"Processed_Text\"]])))\n",
    "print('Std Dev word length of Headlines is {0:.1f}.'.format(np.std([len(headline) for headline in IS_headlines_processed[\"Processed_Text\"]])))\n",
    "print('Max word length of Headlines is {0:.0f}.'.format(np.max([len(headline) for headline in IS_headlines_processed[\"Processed_Text\"]])))\n",
    "print('Average character length of Headlines is {0:.0f}.'.format(np.mean([len(''.join(headline)) for headline in IS_headlines_processed[\"Processed_Text\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6828a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = IS_headlines_processed[IS_headlines_processed[\"Sent\"]==1]\n",
    "#Headlines Size statistics (by class)\n",
    "print('Average word length of Headlines is {0:.0f}.'.format(np.mean([len(headline) for headline in temp[\"Processed_Text\"]])))\n",
    "print('Std Dev word length of Headlines is {0:.1f}.'.format(np.std([len(headline) for headline in temp[\"Processed_Text\"]])))\n",
    "print('Max word length of Headlines is {0:.0f}.'.format(np.max([len(headline) for headline in temp[\"Processed_Text\"]])))\n",
    "print('Average character length of Headlines is {0:.0f}.'.format(np.mean([len(''.join(headline)) for headline in temp[\"Processed_Text\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check specific examples of headlines with given key word\n",
    "keyword = \"finnish\"\n",
    "for headline in IS_headlines_processed[\"title\"]:\n",
    "    if keyword in headline.lower():\n",
    "        print(headline.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34535fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
